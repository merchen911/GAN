import os
import warnings
warnings.filterwarnings("ignore")

import pandas as pds
import numpy as np
from matplotlib import pyplot as plt

import tensorflow as tf
from tensorflow import keras
from tensorflow.examples.tutorials.mnist import input_data

from sklearn.preprocessing import MinMaxScaler

config = tf.ConfigProto()
config.gpu_options.allow_growth = True 
sess = tf.Session(config=config)
tf.keras.backend.set_session(session=sess)


class ACGAN():
    def __init__(self, input_rows, input_cols, input_channels, input_classes, latent_dim=100):
        # Input shape
        self.img_rows = input_rows
        self.img_cols = input_cols
        self.channels = input_channels
        self.img_shape = (self.img_rows, self.img_cols, self.channels)
        self.num_classes = input_classes
        self.latent_dim = latent_dim

        optimizer = keras.optimizers.Adam(learning_rate=0.0002, 
                                          beta_1=0.5)
        losses = ['binary_crossentropy', 'sparse_categorical_crossentropy']

        # Build and compile the discriminator
        self.discriminator = self.build_discriminator()
        self.discriminator.compile(loss=losses,
            optimizer=optimizer,
            metrics=['accuracy'])

        # Build the generator
        self.generator = self.build_generator()

        # The generator takes noise and the target label as input
        # and generates the corresponding digit of that label
        noise = keras.Input(shape=(self.latent_dim,))
        label = keras.Input(shape=(1,))
        img = self.generator([noise, label])

        # For the combined model we will only train the generator
        self.discriminator.trainable = False

        # The discriminator takes generated image as input and determines validity
        # and the label of that image
        valid, target_label = self.discriminator(img)

        # The combined model  (stacked generator and discriminator)
        # Trains the generator to fool the discriminator
        self.combined = keras.Model([noise, label], [valid, target_label])
        self.combined.compile(loss=losses,
            optimizer=optimizer)

    def relu(self,args):
        return tf.nn.leaky_relu(args,alpha=0.2)
    
    def build_generator(self):

        model = keras.Sequential()

        model.add(keras.layers.Dense(2*2*768, activation='relu', input_dim=self.latent_dim))
        model.add(keras.layers.Reshape((2, 2, 768)))
        
        model.add(keras.layers.Conv2DTranspose(384, kernel_size=5, strides=(2,2), 
                                               padding="same", activation=self.relu))
        model.add(keras.layers.BatchNormalization(momentum=0.8))
        
        model.add(keras.layers.Conv2DTranspose(256, kernel_size=5, strides=(2,2), 
                                               padding="same", activation=self.relu))
        model.add(keras.layers.BatchNormalization(momentum=0.8))
        
        model.add(keras.layers.Conv2DTranspose(192, kernel_size=5, strides=(2,2), 
                                               padding="same", activation=self.relu))
        model.add(keras.layers.BatchNormalization(momentum=0.8))
        
                
        model.add(keras.layers.Conv2DTranspose(self.channels, kernel_size=3, strides=(2,2),
                                               padding='same',activation='tanh'))
        
        noise = keras.Input(shape=(self.latent_dim,))
        label = keras.Input(shape=(1,), dtype='int32')
        label_embedding = keras.layers.Flatten()(
            keras.layers.Embedding(self.num_classes, self.latent_dim)(label))

        model_input = keras.layers.multiply([noise, label_embedding])
        img = model(model_input)

        return keras.Model([noise, label], img)

    def build_discriminator(self):

        model = keras.Sequential()

        model.add(keras.layers.Conv2D(16, kernel_size=3, strides=2, 
                         input_shape=self.img_shape, padding="same", activation=self.relu))
        model.add(keras.layers.Dropout(0.5))
        
        model.add(keras.layers.Conv2D(32, kernel_size=3, padding="same",activation=self.relu))
        model.add(keras.layers.Dropout(0.5))
        model.add(keras.layers.BatchNormalization(momentum=0.8))
        
        model.add(keras.layers.Conv2D(64, kernel_size=3, strides=2, padding="same",activation=self.relu))
        model.add(keras.layers.Dropout(0.5))
        model.add(keras.layers.BatchNormalization(momentum=0.8))
        
        model.add(keras.layers.Conv2D(128, kernel_size=3, padding="same",activation=self.relu))
        model.add(keras.layers.Dropout(0.5))
        model.add(keras.layers.BatchNormalization(momentum=0.8))
        
        model.add(keras.layers.Conv2D(256, kernel_size=3, strides=2, padding="same",activation=self.relu))
        model.add(keras.layers.Dropout(0.5))
        model.add(keras.layers.BatchNormalization(momentum=0.8))
                
        model.add(keras.layers.Conv2D(512, kernel_size=3, padding="same",activation=self.relu))
        model.add(keras.layers.Dropout(0.25))

        model.add(keras.layers.Flatten())

        img = keras.Input(shape=self.img_shape)

        # Extract feature representation
        features = model(img)

        # Determine validity and label of the image
        validity = keras.layers.Dense(1, activation="sigmoid")(features)
        label = keras.layers.Dense(self.num_classes+1, activation="softmax")(features)

        return keras.Model(img, [validity, label])

    def train(self, X_train, y_train, epochs, batch_size=128, sample_interval=50):

        # Load the dataset
        #(X_train, y_train), (_, _) = mnist.load_data()
        #X_train, y_train = self.X_train, self.y_train

        # Configure inputs
        X_train = (X_train.astype(np.float32) - 127.5) / 127.5
        y_train = y_train.reshape(-1, 1)

        # Adversarial ground truths
        valid = np.ones((batch_size, 1))
        fake = np.zeros((batch_size, 1))

        # Loss output
        g_loss_epochs = np.zeros((epochs, 1))
        d_loss_epochs = np.zeros((epochs, 1))
        d_real_epochs = np.zeros((epochs, 1))
        d_fake_epochs = np.zeros((epochs, 1))
        for epoch in range(epochs):

            # ---------------------
            #  Train Discriminator
            # ---------------------

            # Select a random batch of images
            idx = np.random.randint(0, X_train.shape[0], batch_size)
            imgs = X_train[idx]

            # Sample noise as generator input
            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))

            # The labels of the digits that the generator tries to create an
            # image representation of
            sampled_labels = np.random.randint(0, self.num_classes, (batch_size, 1))

            # Generate a half batch of new images
            gen_imgs = self.generator.predict([noise, sampled_labels])

            # Image labels. 0-9 if image is valid or 10 if it is generated (fake)
            img_labels = y_train[idx]
            fake_labels = self.num_classes * np.ones(img_labels.shape)

            
#             print(imgs.shape)
            # Train the discriminator
            d_loss_real = self.discriminator.train_on_batch(imgs, [valid, img_labels])
            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, [fake, fake_labels])
            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

            # ---------------------
            #  Train Generator
            # ---------------------

            # Train the generator
            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))
            g_loss = self.combined.train_on_batch([noise, sampled_labels], [valid, sampled_labels])

            #show the final losses
            g_loss_epochs[epoch] = g_loss[0]
            d_loss_epochs[epoch] = d_loss[0]
            d_real_epochs[epoch] = d_loss_real[0]
            d_fake_epochs[epoch] = d_loss_fake[0]

            # If at save interval => save generated image samples
            if epoch % sample_interval == 0:
                # Plot the progress
                print ("Epoch: %d [D loss: %f, acc.: %.2f%%, op_acc: %.2f%%] [G loss: %f]" % (epoch, d_loss[0], 100*d_loss[3], 100*d_loss[4], g_loss[0]))
                #do not save model
                #self.save_model()
                self.display(epoch)

        return g_loss_epochs, d_loss_epochs

    def save_model(self):
        def save(model, model_name):
            model_path = "../saved_model/%s.json" % model_name
            weights_path = "../saved_model/%s_weights.hdf5" % model_name
            options = {"file_arch": model_path,
                        "file_weight": weights_path}
            json_string = model.to_json()
            #
            open(options['file_arch'], 'w').write(json_string)
            model.save_weights(options['file_weight'])

        save(self.generator, "generator")
        save(self.discriminator, "discriminator")


    def display(self,epoch):
        fig,ax=plt.subplots(10,10,figsize=(11,10))
        fig.subplots_adjust(hspace=0.1)
        for row in range(10):
            for col in range(10):
                gen_data=(self.generator.predict([np.random.normal(size=(1,self.latent_dim)),np.array([row])])*127.5+127.5).reshape(32,32,3).astype(int)
                ax[row][col].imshow(gen_data)
                ax[row][col].set_xticks([])
                ax[row][col].set_yticks([])

        fig.suptitle('epoch : %d'%epoch)
        plt.show()
        plt.close()
				
data=np.load(os.path.join('./dataset','cifar-10','cifar10.npy'),allow_pickle=True)
target=np.load(os.path.join('./dataset','cifar-10','cifar10.npy'),allow_pickle=True)
target_subs={i:['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck'][i] for i in range(10)}

acgan=ACGAN(*data.shape[1:],np.unique(target).shape[0],latent_dim=110)
g_loss, d_loss = acgan.train(data, target, epochs=50000, batch_size=100, sample_interval=1000)
